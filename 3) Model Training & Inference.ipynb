{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f29273f7-d4c3-44c4-a113-1e68b4d8e6d0",
   "metadata": {},
   "source": [
    "# üß† Waste Detection Project ‚Äì Model Training & Inference\n",
    "\n",
    "Welcome to the **Model Training & Inference** stage of the Waste Detection AI Workshop. In this notebook, we‚Äôll prepare the data and train a YOLOv11 model to detect different types of waste from images.\n",
    "\n",
    "In this notebook, we:\n",
    "- Split the dataset into train, validation, and test sets.\n",
    "- Create a data.yaml config file for YOLO.\n",
    "- Train a YOLO model using the Ultralytics package.\n",
    "- Run inference on test images.\n",
    "\n",
    "üìÅ **Before you begin**, make sure your dataset (after augmentation) is organized as follows:\n",
    "```\n",
    "Garbage-Dataset/\n",
    "‚îú‚îÄ‚îÄ augmented_images/\n",
    "‚îÇ ‚îú‚îÄ‚îÄ biological_001.jpeg\n",
    "‚îÇ ‚îú‚îÄ‚îÄ biological_002.jpeg\n",
    "‚îÇ ‚îú‚îÄ‚îÄ ...\n",
    "‚îú‚îÄ‚îÄ augmented_labels/\n",
    "‚îÇ ‚îú‚îÄ‚îÄ biological_001.txt\n",
    "‚îÇ ‚îú‚îÄ‚îÄ biological_002.txt\n",
    "‚îÇ ‚îú‚îÄ‚îÄ ...\n",
    "```\n",
    "\n",
    "> ‚úÖ Make sure the EDA and Data Augmentation steps are complete before proceeding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05eceb26-a5bf-441e-915c-036066891d83",
   "metadata": {},
   "source": [
    "## üì• Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58644d2e-2052-4b24-8c69-a401e77b964b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for splitting and YOLO\n",
    "!pip install scikit-learn ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028857a2-1592-4d35-a7d6-1f5d19adf095",
   "metadata": {},
   "source": [
    "## Split Dataset into Train / Val / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa6083b-5474-448f-ae5d-6f4e2fe0bd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Original dataset (augmented)\n",
    "image_dir = 'Garbage-Dataset/augmented_images/'\n",
    "label_dir = 'Garbage-Dataset/augmented_labels/'\n",
    "\n",
    "# Target split folders\n",
    "train_image_dir = 'Garbage-Dataset/train/images/'\n",
    "val_image_dir = 'Garbage-Dataset/val/images/'\n",
    "test_image_dir = 'Garbage-Dataset/test/images/'\n",
    "\n",
    "train_label_dir = 'Garbage-Dataset/train/labels/'\n",
    "val_label_dir = 'Garbage-Dataset/val/labels/'\n",
    "test_label_dir = 'Garbage-Dataset/test/labels/'\n",
    "\n",
    "# Create necessary directories\n",
    "for path in [train_image_dir, val_image_dir, test_image_dir, train_label_dir, val_label_dir, test_label_dir]:\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# Get image and label files\n",
    "image_files = [f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "label_files = [f.rsplit('.', 1)[0] + '.txt' for f in image_files]\n",
    "\n",
    "# Ensure all label files exist\n",
    "assert all(os.path.exists(os.path.join(label_dir, f)) for f in label_files), \"Missing label files\"\n",
    "\n",
    "# Split: 70% train, 20% val, 10% test\n",
    "train_imgs, temp_imgs = train_test_split(image_files, test_size=0.3, random_state=42)\n",
    "val_imgs, test_imgs = train_test_split(temp_imgs, test_size=1/3, random_state=42)\n",
    "\n",
    "# Move files\n",
    "def move_files(images, src_img_dir, src_lbl_dir, dst_img_dir, dst_lbl_dir):\n",
    "    for img in images:\n",
    "        base = img.rsplit('.', 1)[0]\n",
    "        lbl = base + '.txt'\n",
    "        shutil.copy(os.path.join(src_img_dir, img), os.path.join(dst_img_dir, img))\n",
    "        shutil.copy(os.path.join(src_lbl_dir, lbl), os.path.join(dst_lbl_dir, lbl))\n",
    "\n",
    "move_files(train_imgs, image_dir, label_dir, train_image_dir, train_label_dir)\n",
    "move_files(val_imgs, image_dir, label_dir, val_image_dir, val_label_dir)\n",
    "move_files(test_imgs, image_dir, label_dir, test_image_dir, test_label_dir)\n",
    "\n",
    "print(\"‚úÖ Dataset split complete: Train (70%), Val (20%), Test (10%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1cd6c4-884d-4e03-96c4-cd3b31285775",
   "metadata": {},
   "source": [
    "## Create data.yaml for YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2785ce59-c0f6-4164-9b94-3a731daf749f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_yaml = \"\"\"\n",
    "path: Garbage-Dataset\n",
    "train: train/images\n",
    "val: val/images\n",
    "test: test/images\n",
    "\n",
    "nc: 7\n",
    "names:\n",
    "  0: 'biological'\n",
    "  1: 'cardboard'\n",
    "  2: 'glass'\n",
    "  3: 'metal'\n",
    "  4: 'paper'\n",
    "  5: 'plastic'\n",
    "  6: 'trash'\n",
    "\"\"\"\n",
    "\n",
    "with open(\"data.yaml\", \"w\") as f:\n",
    "    f.write(data_yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23978863-ef98-4e40-a205-db7aad134856",
   "metadata": {},
   "source": [
    "## üö® Train YOLO Model\n",
    "You can change the model to any of the following depending on your system's power:\n",
    "```\n",
    "- yolo11n.pt (nano - fastest)\n",
    "- yolo11s.pt (small)\n",
    "- yolo11m.pt (medium)\n",
    "- yolo11l.pt (large)\n",
    "- yolo11x.pt (extra large)\n",
    "```\n",
    "\n",
    "```pip install numpy==1.26.4``` (ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcad6cd-f486-4d47-81cd-fa2a4e047c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo detect train data=data.yaml model=yolo11n.pt epochs=2 imgsz=640"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e9e041-1046-4b5a-ac75-a21563564b36",
   "metadata": {},
   "source": [
    "## üîç Run Inference on a Test Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907abbe5-cef0-4142-bf80-c46636d363e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "# Display the original image before running inference\n",
    "Image(filename='Garbage-Dataset/test/images/aug_0_cardboard_032.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22667c9e-e4ef-41bd-ad46-a5550f45f91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo detect predict model=runs/detect/train/weights/best.pt source=Garbage-Dataset/test/images/aug_0_cardboard_032.jpg\n",
    "Image(filename='runs/detect/predict/aug_0_cardboard_032.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32d90c1-f47e-4fbf-b217-bc080906356d",
   "metadata": {},
   "source": [
    "## ‚úÖ Model Training & Inference Completed!\n",
    "\n",
    "### You‚Äôve now successfully trained a YOLO model and run inference on a sample image.\n",
    "\n",
    "#### üì¶ **Next Step**: Proceed to the garbage-detection-app directory to integrate the trained model into a GUI for deployment.\n",
    "\n",
    "#### Make sure the trained model weights (best.pt) are copied into the app folder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "garbage-project",
   "language": "python",
   "name": "garbage-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
