{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f29273f7-d4c3-44c4-a113-1e68b4d8e6d0",
   "metadata": {},
   "source": [
    "# Garbage Detection Model with YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05eceb26-a5bf-441e-915c-036066891d83",
   "metadata": {},
   "source": [
    "## Preparing the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f71821b-d28a-4bc0-b7e1-0678ac30fa43",
   "metadata": {},
   "source": [
    "garbage-dataset/\n",
    "├── augmented_images/\n",
    "│   ├── biological_001.jpeg\n",
    "│   ├── biological_002.jpeg\n",
    "│   ├── biological_003.jpeg\n",
    "│   ├── biological_004.jpeg\n",
    "│   └── ...\n",
    "└── augmented_labels/\n",
    "    ├── biological_001.txt\n",
    "    ├── biological_002.txt\n",
    "    ├── biological_003.txt\n",
    "    ├── biological_004.txt\n",
    "    └── ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58644d2e-2052-4b24-8c69-a401e77b964b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install scikit\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028857a2-1592-4d35-a7d6-1f5d19adf095",
   "metadata": {},
   "source": [
    "## Split dataset into train, val and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa6083b-5474-448f-ae5d-6f4e2fe0bd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define paths to your original dataset\n",
    "image_dir = 'garbage-dataset/augmented_images/'\n",
    "label_dir = 'garbage-dataset/augmented_labels/'\n",
    "\n",
    "# Define paths to your new train, val, and test directories\n",
    "train_image_dir = 'garbage-dataset/train/images/'\n",
    "val_image_dir = 'garbage-dataset/val/images/'\n",
    "test_image_dir = 'garbage-dataset/test/images/'\n",
    "\n",
    "train_label_dir = 'garbage-dataset/train/labels/'\n",
    "val_label_dir = 'garbage-dataset/val/labels/'\n",
    "test_label_dir = 'garbage-dataset/test/labels/'\n",
    "\n",
    "# Create train, val, and test directories if they don't exist\n",
    "os.makedirs(train_image_dir, exist_ok=True)\n",
    "os.makedirs(val_image_dir, exist_ok=True)\n",
    "os.makedirs(test_image_dir, exist_ok=True)\n",
    "\n",
    "os.makedirs(train_label_dir, exist_ok=True)\n",
    "os.makedirs(val_label_dir, exist_ok=True)\n",
    "os.makedirs(test_label_dir, exist_ok=True)\n",
    "\n",
    "# Get list of image files (ensure both image and label have same filename)\n",
    "image_files = [f for f in os.listdir(image_dir) if f.endswith(('.jpeg', '.jpg', '.png'))]\n",
    "label_files = [f.replace('.jpeg', '.txt').replace('.jpg', '.txt').replace('.png', '.txt') for f in image_files]\n",
    "\n",
    "# Ensure that each image has a corresponding label file\n",
    "assert all(os.path.exists(os.path.join(label_dir, label)) for label in label_files), \"Some label files are missing!\"\n",
    "\n",
    "# Split the dataset into 70% train and 30% (val + test)\n",
    "train_images, temp_images = train_test_split(image_files, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split the 30% into 20% validation and 10% test\n",
    "val_images, test_images = train_test_split(temp_images, test_size=1/3, random_state=42)\n",
    "\n",
    "# Move the files to respective directories\n",
    "for img_file in train_images:\n",
    "    shutil.move(os.path.join(image_dir, img_file), os.path.join(train_image_dir, img_file))\n",
    "    shutil.move(os.path.join(label_dir, img_file.replace('.jpeg', '.txt').replace('.jpg', '.txt').replace('.png', '.txt')),\n",
    "                os.path.join(train_label_dir, img_file.replace('.jpeg', '.txt').replace('.jpg', '.txt').replace('.png', '.txt')))\n",
    "\n",
    "for img_file in val_images:\n",
    "    shutil.move(os.path.join(image_dir, img_file), os.path.join(val_image_dir, img_file))\n",
    "    shutil.move(os.path.join(label_dir, img_file.replace('.jpeg', '.txt').replace('.jpg', '.txt').replace('.png', '.txt')),\n",
    "                os.path.join(val_label_dir, img_file.replace('.jpeg', '.txt').replace('.jpg', '.txt').replace('.png', '.txt')))\n",
    "\n",
    "for img_file in test_images:\n",
    "    shutil.move(os.path.join(image_dir, img_file), os.path.join(test_image_dir, img_file))\n",
    "    shutil.move(os.path.join(label_dir, img_file.replace('.jpeg', '.txt').replace('.jpg', '.txt').replace('.png', '.txt')),\n",
    "                os.path.join(test_label_dir, img_file.replace('.jpeg', '.txt').replace('.jpg', '.txt').replace('.png', '.txt')))\n",
    "\n",
    "print(\"Dataset split complete! Train: 70%, Val: 20%, Test: 10%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2375cb-8568-4ca7-8613-a2d68bf874ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2785ce59-c0f6-4164-9b94-3a731daf749f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_yaml = \"\"\"\n",
    "path: garbage-dataset/\n",
    "train: train/images\n",
    "val: val/images\n",
    "test: test/images\n",
    "\n",
    "nc: 7\n",
    "names:\n",
    "  0: 'biological'\n",
    "  1: 'cardboard'\n",
    "  2: 'glass'\n",
    "  3: 'metal'\n",
    "  4: 'paper'\n",
    "  5: 'plastic'\n",
    "  6: 'trash'\n",
    "\"\"\"\n",
    "\n",
    "with open(\"data.yaml\", \"w\") as f:\n",
    "    f.write(data_yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23978863-ef98-4e40-a205-db7aad134856",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcad6cd-f486-4d47-81cd-fa2a4e047c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo detect train data=data.yaml model=yolo11n.pt epochs=50 imgsz=640"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e9e041-1046-4b5a-ac75-a21563564b36",
   "metadata": {},
   "source": [
    "## Running Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907abbe5-cef0-4142-bf80-c46636d363e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "# Display the original image before running inference\n",
    "Image(filename='garbage-dataset/test/images/aug_0_biological_016.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22667c9e-e4ef-41bd-ad46-a5550f45f91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo detect predict model=runs/detect/train/weights/best.pt source=garbage-dataset/test/images/aug_0_biological_016.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7193ce-d005-4698-a237-39a8690ceccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='runs/detect/predict/aug_0_biological_016.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8c4188-f04e-42b4-91b8-fd40e8974492",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "garbage-project",
   "language": "python",
   "name": "garbage-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
