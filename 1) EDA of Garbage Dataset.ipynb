{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98cd16e7-467d-45b2-8695-4bb93d1b2970",
   "metadata": {},
   "source": [
    "# üóëÔ∏è Waste Detection Project ‚Äì EDA (Local Version)\n",
    "\n",
    "Welcome to the **Exploratory Data Analysis (EDA)** notebook for the Waste Detection AI Workshop project. This version is designed for running locally (not in Google Colab).\n",
    "\n",
    "### üìå Objectives of this Notebook:\n",
    "- Load and preview the garbage dataset\n",
    "- Understand the dataset structure, classes, and sample distribution\n",
    "- Visualize bounding boxes\n",
    "- Identify missing files (unlabeled images or labels without images)\n",
    "\n",
    "> This is the first step in a 4-part series:\n",
    "> 1. EDA of Garbage Dataset (you are here)\n",
    "> 2. Data Augmentation\n",
    "> 3. Model Training & Inference\n",
    "> 4. GUI Deployment\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc4572e-9fe2-45c0-bfdd-df91b1e1a40b",
   "metadata": {},
   "source": [
    "## üì• Step 1: Download & Annotate the Dataset\n",
    "\n",
    "1. Download the Garbage Dataset from this shared Google Drive link:  \n",
    "   üëâ [Download Dataset](https://drive.google.com/drive/u/1/folders/13C1MaoC5YKQlX1mRIE2nGY23gR9tfGeH)\n",
    "\n",
    "2. Use [https://www.makesense.ai](https://www.makesense.ai) or Roboflow to annotate **only the `glass` class** (approx. 50 images missing this label).\n",
    "\n",
    "3. Once complete:\n",
    "   - Place all **images** in: `garbage-dataset/images/`\n",
    "   - Place all **annotations** in: `garbage-dataset/labels/`\n",
    "\n",
    "üéØ This manual annotation step is crucial to make sure our model correctly recognizes glass waste. Good luck, and enjoy the process!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9041b2e3-c2cc-4e3b-940a-4de4299e290b",
   "metadata": {},
   "source": [
    "## üìä Step 2: Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61ce274-5408-4a3f-94f7-78b1bdfeaebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "base_path = \"Garbage-Dataset\"\n",
    "image_dir = os.path.join(base_path, \"images\")\n",
    "label_dir = os.path.join(base_path, \"labels\")\n",
    "\n",
    "image_files = glob(os.path.join(image_dir, \"*.jpg\"))\n",
    "label_files = glob(os.path.join(label_dir, \"*.txt\"))\n",
    "\n",
    "print(f\"Total images: {len(image_files)}\")\n",
    "print(f\"Total label files: {len(label_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d31e25-c7df-462c-a7f6-17bc9ffe6c19",
   "metadata": {},
   "source": [
    "## üìà Step 3: Check Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25bc34c-8eec-486c-8ea5-d2583407b871",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the class names\n",
    "classes = ['biological', 'cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
    "class_counts = {i: 0 for i in range(len(classes))}\n",
    "\n",
    "# Count class occurrences\n",
    "for label_file in label_files:\n",
    "    with open(label_file, 'r') as f:\n",
    "        for line in f:\n",
    "            class_id = int(line.split()[0])\n",
    "            class_counts[class_id] += 1\n",
    "\n",
    "# Convert to DataFrame for plotting\n",
    "df = pd.DataFrame({\n",
    "    'Class': [classes[i] for i in class_counts],\n",
    "    'Count': list(class_counts.values())\n",
    "})\n",
    "\n",
    "# Plot\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(df['Class'], df['Count'], color='teal')\n",
    "plt.title('Number of Bounding Boxes per Class')\n",
    "plt.xlabel('Waste Class')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c716baf3-73a3-473e-b045-c5e29d2febd1",
   "metadata": {},
   "source": [
    "## üñºÔ∏è Step 4: Visualize Sample Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fef0647-e77c-4f36-b99d-55dd4ca1d14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Draw YOLO Boxes\n",
    "\n",
    "def draw_yolo_boxes(img_path, label_path):\n",
    "    image = cv2.imread(img_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    h, w, _ = image.shape\n",
    "\n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            cls_id, x, y, bw, bh = map(float, line.strip().split())\n",
    "            x1 = int((x - bw / 2) * w)\n",
    "            y1 = int((y - bh / 2) * h)\n",
    "            x2 = int((x + bw / 2) * w)\n",
    "            y2 = int((y + bh / 2) * h)\n",
    "            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(image, classes[int(cls_id)], (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
    "    return image\n",
    "\n",
    "\n",
    "# Sample image and label\n",
    "\n",
    "sample_img = image_files[75]\n",
    "sample_label = sample_img.replace(\"images\", \"labels\").replace(\".jpg\", \".txt\")\n",
    "\n",
    "# Draw\n",
    "annotated = draw_yolo_boxes(sample_img, sample_label)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.imshow(annotated)\n",
    "plt.axis('off')\n",
    "plt.title('Sample Image with Bounding Boxes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5370ba-2d01-4a54-b67e-8ee890d65816",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è Step 5: Check for Missing Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a79d3b7-4904-4c18-9473-e5d83c60a4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_base = set(os.path.basename(f).replace('.jpg', '') for f in image_files)\n",
    "label_base = set(os.path.basename(f).replace('.txt', '') for f in label_files)\n",
    "\n",
    "missing_labels = image_base - label_base\n",
    "missing_images = label_base - image_base\n",
    "\n",
    "print(f\"Images without labels: {len(missing_labels)}\")\n",
    "print(f\"Labels without images: {len(missing_images)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f407d7-6a4a-428a-a343-4903ef533c9c",
   "metadata": {},
   "source": [
    "## ‚úÖ Next Step\n",
    "\n",
    "### Continue to the next notebook to apply image and label augmentations for training!\n",
    "\n",
    "#### üì¶ **Next Step: [2) Data Augmentation.ipynb](./2_Data_Augmentation.ipynb)**\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-project",
   "language": "python",
   "name": "llm-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
