{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d16502e7-736d-4293-bdf3-7597c5f9f70b",
   "metadata": {},
   "source": [
    "# Real-Time Object Detection using YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36ff964-18b0-40fe-94a7-f8644de9dcda",
   "metadata": {},
   "source": [
    "### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b128c030-32b8-4ede-89ba-5f97350d9432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50824a25-9285-4f1e-b391-a5fda327ac73",
   "metadata": {},
   "source": [
    "### Load the YOLO Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012af835-0d35-4b6b-ac26-e9f19021ba02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained YOLO model (ensure your 'best.pt' file is in the same directory)\n",
    "model = YOLO(\"runs/detect/train/weights/best.pt\")\n",
    "\n",
    "# Waste classes (these should match the labels your model was trained on)\n",
    "classes = ['biological', 'cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0a1e9c-635e-4f9a-a875-ac9fdb742419",
   "metadata": {},
   "source": [
    "### Set Up Webcam Capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242c3d04-27bd-47c1-b2c4-28160d558659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up webcam capture\n",
    "cap = cv2.VideoCapture(0)  # 0 is the default camera\n",
    "\n",
    "# Check if webcam is opened correctly\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9eb4ce-3414-4d05-a6db-5c8285487af9",
   "metadata": {},
   "source": [
    "### Real-Time Inference and Display in Jupyter Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c8cf2e-edc3-4ffa-874e-bc374785c18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to detect objects and take a snapshot every 10 seconds\n",
    "def detect_objects():\n",
    "    start_time = time.time()  # Store the start time\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            # Capture frame-by-frame\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Failed to capture frame.\")\n",
    "                break\n",
    "\n",
    "            current_time = time.time()\n",
    "\n",
    "            # If 10 seconds have passed, process and show the snapshot\n",
    "            if current_time - start_time >= 10:\n",
    "                # Perform inference\n",
    "                results = model.predict(source=frame, verbose=False)\n",
    "                output = results[0]\n",
    "\n",
    "                # Draw bounding boxes and labels\n",
    "                for box, conf, cls in zip(output.boxes.xyxy, output.boxes.conf, output.boxes.cls):\n",
    "                    x1, y1, x2, y2 = map(int, box)\n",
    "                    class_name = classes[int(cls)]\n",
    "                    color = (0, 255, 0)  # Green boxes for all classes\n",
    "\n",
    "                    # Draw bounding box\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "\n",
    "                    # Label with class name and confidence\n",
    "                    label = f\"{class_name}: {conf:.2f}\"\n",
    "                    cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "                # Convert BGR to RGB for display in Jupyter (OpenCV uses BGR by default)\n",
    "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                # Display the resulting frame using matplotlib\n",
    "                plt.imshow(frame_rgb)\n",
    "                plt.axis('off')  # Hide axes\n",
    "                plt.show()\n",
    "\n",
    "                start_time = current_time  # Reset the start time for next snapshot\n",
    "\n",
    "            # Exit if 'q' is pressed\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    finally:\n",
    "        # Release the webcam and close any OpenCV windows\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "# Run the detection function (snapshot every 10 seconds)\n",
    "detect_objects()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5c6a0f-57b7-45bf-a5b7-008a91ca81f6",
   "metadata": {},
   "source": [
    "### Stopping the Webcam Capture\n",
    "\n",
    "To stop the webcam, you can press `q` on your keyboard. It will gracefully close the webcam feed and all windows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "garbage-project",
   "language": "python",
   "name": "garbage-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
