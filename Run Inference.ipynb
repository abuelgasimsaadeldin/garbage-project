{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d59a9b-1a65-42f0-9061-36a62afffa0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d024f386-f1d8-4b55-81be-e63660a2a83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 61.0ms\n",
      "Speed: 352.6ms preprocess, 61.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Abuelgasim\\miniconda3\\envs\\garbage-project\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\Abuelgasim\\AppData\\Local\\Temp\\ipykernel_32660\\3747457531.py\", line 41, in capture_image\n",
      "    results = self.detect_objects(frame)\n",
      "  File \"C:\\Users\\Abuelgasim\\AppData\\Local\\Temp\\ipykernel_32660\\3747457531.py\", line 83, in detect_objects\n",
      "    result.render()  # Draw boxes and labels on the image\n",
      "  File \"C:\\Users\\Abuelgasim\\miniconda3\\envs\\garbage-project\\lib\\site-packages\\ultralytics\\utils\\__init__.py\", line 274, in __getattr__\n",
      "    raise AttributeError(f\"'{name}' object has no attribute '{attr}'. See valid attributes below.\\n{self.__doc__}\")\n",
      "AttributeError: 'Results' object has no attribute 'render'. See valid attributes below.\n",
      "\n",
      "    A class for storing and manipulating inference results.\n",
      "\n",
      "    This class provides comprehensive functionality for handling inference results from various\n",
      "    Ultralytics models, including detection, segmentation, classification, and pose estimation.\n",
      "    It supports visualization, data export, and various coordinate transformations.\n",
      "\n",
      "    Attributes:\n",
      "        orig_img (np.ndarray): The original image as a numpy array.\n",
      "        orig_shape (tuple[int, int]): Original image shape in (height, width) format.\n",
      "        boxes (Boxes | None): Detected bounding boxes.\n",
      "        masks (Masks | None): Segmentation masks.\n",
      "        probs (Probs | None): Classification probabilities.\n",
      "        keypoints (Keypoints | None): Detected keypoints.\n",
      "        obb (OBB | None): Oriented bounding boxes.\n",
      "        speed (dict): Dictionary containing inference speed information.\n",
      "        names (dict): Dictionary mapping class indices to class names.\n",
      "        path (str): Path to the input image file.\n",
      "        save_dir (str | None): Directory to save results.\n",
      "\n",
      "    Methods:\n",
      "        update: Update the Results object with new detection data.\n",
      "        cpu: Return a copy of the Results object with all tensors moved to CPU memory.\n",
      "        numpy: Convert all tensors in the Results object to numpy arrays.\n",
      "        cuda: Move all tensors in the Results object to GPU memory.\n",
      "        to: Move all tensors to the specified device and dtype.\n",
      "        new: Create a new Results object with the same image, path, names, and speed attributes.\n",
      "        plot: Plot detection results on an input RGB image.\n",
      "        show: Display the image with annotated inference results.\n",
      "        save: Save annotated inference results image to file.\n",
      "        verbose: Return a log string for each task in the results.\n",
      "        save_txt: Save detection results to a text file.\n",
      "        save_crop: Save cropped detection images to specified directory.\n",
      "        summary: Convert inference results to a summarized dictionary.\n",
      "        to_df: Convert detection results to a Polars Dataframe.\n",
      "        to_json: Convert detection results to JSON format.\n",
      "        to_csv: Convert detection results to a CSV format.\n",
      "\n",
      "    Examples:\n",
      "        >>> results = model(\"path/to/image.jpg\")\n",
      "        >>> result = results[0]  # Get the first result\n",
      "        >>> boxes = result.boxes  # Get the boxes for the first result\n",
      "        >>> masks = result.masks  # Get the masks for the first result\n",
      "        >>> for result in results:\n",
      "        >>>     result.plot()  # Plot detection results\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load your custom YOLOv11 model using the Ultralytics YOLO class\n",
    "model = YOLO('yolo11n.pt')  # Replace with the path to your .pt file\n",
    "\n",
    "# Set up the GUI\n",
    "class ObjectDetectionApp:\n",
    "    def __init__(self, window, window_title):\n",
    "        self.window = window\n",
    "        self.window.title(window_title)\n",
    "\n",
    "        # Add a canvas for displaying images\n",
    "        self.canvas = tk.Canvas(window, width=640, height=480)\n",
    "        self.canvas.pack()\n",
    "\n",
    "        # Add buttons for taking a picture and video detection\n",
    "        self.btn_capture = tk.Button(window, text=\"Capture Image\", width=20, command=self.capture_image)\n",
    "        self.btn_capture.pack()\n",
    "\n",
    "        self.btn_video = tk.Button(window, text=\"Start Video\", width=20, command=self.start_video)\n",
    "        self.btn_video.pack()\n",
    "\n",
    "        # OpenCV video capture\n",
    "        self.cap = cv2.VideoCapture(0)  # 0 for default webcam\n",
    "        self.is_video_running = False\n",
    "\n",
    "        self.window.mainloop()\n",
    "\n",
    "    def capture_image(self):\n",
    "        \"\"\"Capture an image from webcam and run object detection\"\"\"\n",
    "        ret, frame = self.cap.read()\n",
    "        if not ret:\n",
    "            messagebox.showerror(\"Error\", \"Failed to capture image\")\n",
    "            return\n",
    "        \n",
    "        # Run object detection\n",
    "        results = self.detect_objects(frame)\n",
    "\n",
    "        # Convert to Tkinter format and display\n",
    "        self.display_image(results.imgs[0])\n",
    "\n",
    "    def start_video(self):\n",
    "        \"\"\"Start the video feed and run object detection on each frame\"\"\"\n",
    "        self.is_video_running = True\n",
    "        self.video_loop()\n",
    "\n",
    "    def stop_video(self):\n",
    "        \"\"\"Stop video feed\"\"\"\n",
    "        self.is_video_running = False\n",
    "\n",
    "    def video_loop(self):\n",
    "        \"\"\"Process video frame by frame\"\"\"\n",
    "        ret, frame = self.cap.read()\n",
    "        if not ret:\n",
    "            messagebox.showerror(\"Error\", \"Failed to capture frame\")\n",
    "            return\n",
    "\n",
    "        # Run object detection\n",
    "        results = self.detect_objects(frame)\n",
    "\n",
    "        # Convert to Tkinter format and display\n",
    "        self.display_image(results.imgs[0])\n",
    "\n",
    "        if self.is_video_running:\n",
    "            self.window.after(10, self.video_loop)\n",
    "\n",
    "    def detect_objects(self, img):\n",
    "        \"\"\"Run the YOLO model for object detection\"\"\"\n",
    "        # Convert image to RGB (OpenCV uses BGR)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Run detection\n",
    "        results = model(img_rgb)  # This is a list of results, so we need to access the first element\n",
    "\n",
    "        # results[0] contains the actual result, which has the 'render()' method\n",
    "        result = results[0]\n",
    "\n",
    "        # Annotate the image with the detected objects\n",
    "        result.render()  # Draw boxes and labels on the image\n",
    "\n",
    "        return result\n",
    "\n",
    "    def display_image(self, img):\n",
    "        \"\"\"Display the image in the Tkinter canvas\"\"\"\n",
    "        img = Image.fromarray(img)\n",
    "        img = img.resize((640, 480))  # Resize to fit canvas\n",
    "\n",
    "        # Convert image to Tkinter format\n",
    "        imgtk = ImageTk.PhotoImage(image=img)\n",
    "\n",
    "        # Update canvas with the image\n",
    "        self.canvas.create_image(0, 0, anchor=tk.NW, image=imgtk)\n",
    "        self.canvas.imgtk = imgtk  # Keep a reference to avoid garbage collection\n",
    "\n",
    "# Create and run the GUI\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = ObjectDetectionApp(root, \"YOLOv11 Object Detection\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242c3d04-27bd-47c1-b2c4-28160d558659",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "garbage-project",
   "language": "python",
   "name": "garbage-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
